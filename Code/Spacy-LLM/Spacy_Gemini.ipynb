{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install google-generativeai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-T4LUD1DYoZ",
        "outputId": "ec21c61c-8292-4a20-993f-6982a555300e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.26.0)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.184.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.11.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (2.32.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.75.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.10.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy_llm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrcuJTNMsr_w",
        "outputId": "7619e376-8c81-4d39-cbd8-0a16d3a8a280"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting spacy_llm\n",
            "  Downloading spacy_llm-0.7.3-py2.py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: spacy<4.0,>=3.5 in /usr/local/lib/python3.12/dist-packages (from spacy_llm) (3.8.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy_llm) (3.1.6)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from spacy_llm) (0.1.5)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from confection<1.0.0,>=0.1.3->spacy_llm) (2.11.10)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from confection<1.0.0,>=0.1.3->spacy_llm) (2.5.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy<4.0,>=3.5->spacy_llm) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy<4.0,>=3.5->spacy_llm) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy<4.0,>=3.5->spacy_llm) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy<4.0,>=3.5->spacy_llm) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy<4.0,>=3.5->spacy_llm) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy<4.0,>=3.5->spacy_llm) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy<4.0,>=3.5->spacy_llm) (1.1.3)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy<4.0,>=3.5->spacy_llm) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy<4.0,>=3.5->spacy_llm) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy<4.0,>=3.5->spacy_llm) (0.19.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from spacy<4.0,>=3.5->spacy_llm) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy<4.0,>=3.5->spacy_llm) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy<4.0,>=3.5->spacy_llm) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy<4.0,>=3.5->spacy_llm) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy<4.0,>=3.5->spacy_llm) (25.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from spacy<4.0,>=3.5->spacy_llm) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy_llm) (3.0.3)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.12/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<4.0,>=3.5->spacy_llm) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->confection<1.0.0,>=0.1.3->spacy_llm) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->confection<1.0.0,>=0.1.3->spacy_llm) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->confection<1.0.0,>=0.1.3->spacy_llm) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->confection<1.0.0,>=0.1.3->spacy_llm) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0,>=3.5->spacy_llm) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0,>=3.5->spacy_llm) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0,>=3.5->spacy_llm) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0,>=3.5->spacy_llm) (2025.10.5)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<4.0,>=3.5->spacy_llm) (1.3.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4.0,>=3.5->spacy_llm) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4.0,>=3.5->spacy_llm) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4.0,>=3.5->spacy_llm) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4.0,>=3.5->spacy_llm) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4.0,>=3.5->spacy_llm) (7.3.1)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4.0,>=3.5->spacy_llm) (1.3.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0,>=3.5->spacy_llm) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0,>=3.5->spacy_llm) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<4.0,>=3.5->spacy_llm) (1.17.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0,>=3.5->spacy_llm) (0.1.2)\n",
            "Downloading spacy_llm-0.7.3-py2.py3-none-any.whl (255 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.9/255.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: spacy_llm\n",
            "Successfully installed spacy_llm-0.7.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gb_7IxrEsle7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "import spacy\n",
        "import spacy_llm\n",
        "from spacy_llm.registry import registry\n",
        "from spacy.tokens import Doc\n",
        "from typing import Iterable\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "gemini_key = userdata.get('GEMINI_API')"
      ],
      "metadata": {
        "id": "yc1RHgWesmRw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Gemini Model\n",
        "class GeminiModel:\n",
        "    def __init__(self, api_key: str):\n",
        "        print(f\"Initializing Gemini...\")\n",
        "        genai.configure(api_key=api_key)\n",
        "        self.model = genai.GenerativeModel(\"gemini-2.5-flash-lite\")\n",
        "        print(\"Gemini ready\")\n",
        "\n",
        "    def __call__(self, prompts: Iterable[str]):\n",
        "        responses = []\n",
        "        for prompt in prompts:\n",
        "            if isinstance(prompt, list):\n",
        "                prompt = prompt[0]\n",
        "            try:\n",
        "                response = self.model.generate_content(prompt)\n",
        "                responses.append(response.text.strip())\n",
        "            except Exception as e:\n",
        "                print(f\"Error generating content: {e}\")\n",
        "                responses.append(\"Error generating response\")\n",
        "        return responses\n"
      ],
      "metadata": {
        "id": "VoRVc9k3IGbN"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Register Gemini model\n",
        "@registry.llm_models(\"custom.Gemini.v1\")\n",
        "def gemini_model(api_key: str):\n",
        "    return GeminiModel(api_key)\n",
        "\n",
        "# Custom Triplet Extraction Task\n",
        "@registry.llm_tasks(\"custom.TripletExtraction.v1\")\n",
        "def make_triplet_task():\n",
        "    return TripletExtractionTask()\n"
      ],
      "metadata": {
        "id": "arDXzgxhIOsB"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TripletExtractionTask:\n",
        "    def __init__(self):\n",
        "        if not Doc.has_extension(\"triplets\"):\n",
        "            Doc.set_extension(\"triplets\", default=[])\n",
        "\n",
        "        # Load SpaCy model for entity detection\n",
        "        self.nlp_filter = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "        # Action verbs that indicate meaningful organizational relationships\n",
        "        self.meaningful_verbs = {\n",
        "            'funds', 'supports', 'partners', 'collaborates', 'establishes', 'creates',\n",
        "            'develops', 'provides', 'delivers', 'launches', 'invests', 'awards',\n",
        "            'trains', 'educates', 'connects', 'facilitates', 'enables', 'selects',\n",
        "            'accelerates', 'incubates', 'scales', 'finances', 'grants', 'coordinates',\n",
        "            'manages', 'operates', 'builds', 'implements', 'deploys', 'organizes'\n",
        "        }\n",
        "\n",
        "    def _has_meaningful_action(self, text):\n",
        "        \"\"\"Check if sentence contains meaningful action verbs\"\"\"\n",
        "        doc = self.nlp_filter(text.lower())\n",
        "        # Check if any meaningful verb is in the sentence\n",
        "        for token in doc:\n",
        "            if token.lemma_ in self.meaningful_verbs:\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def _has_entities(self, text):\n",
        "        \"\"\"Check if text has at least 2 relevant entities\"\"\"\n",
        "        doc = self.nlp_filter(text)\n",
        "        entities = [ent for ent in doc.ents if ent.label_ in [\"ORG\", \"PERSON\", \"GPE\", \"NORP\", \"PRODUCT\"]]\n",
        "        return len(entities) >= 2\n",
        "\n",
        "    def generate_prompts(self, docs: Iterable[Doc]) -> Iterable[str]:\n",
        "        prompts = []\n",
        "        for doc in docs:\n",
        "            # Process through nlp_filter\n",
        "            processed_doc = self.nlp_filter(doc.text)\n",
        "            sentences = [sent.text.strip() for sent in processed_doc.sents]\n",
        "\n",
        "            # STRICT filtering: Must have entities AND meaningful action verbs\n",
        "            candidate_sentences = [\n",
        "                sent for sent in sentences\n",
        "                if len(sent) > 40 and\n",
        "                self._has_entities(sent) and\n",
        "                self._has_meaningful_action(sent)\n",
        "            ]\n",
        "\n",
        "            if not candidate_sentences:\n",
        "                prompts.append(\"No relationships found.\")\n",
        "                continue\n",
        "\n",
        "            # Process up to 10 high-quality sentences\n",
        "            filtered_text = \" \".join(candidate_sentences[:10])\n",
        "\n",
        "            # Enhanced prompt with better examples\n",
        "            prompt = f\"\"\"Extract ONLY strategic organizational relationships that show ongoing institutional practices.\n",
        "\n",
        "WHAT TO EXTRACT:\n",
        "Focus ONLY on relationships that show:\n",
        "- Funding/Investment: \"X funds Y\", \"X invests in Y\"\n",
        "- Support/Acceleration: \"X supports Y\", \"X accelerates Y\"\n",
        "- Partnership: \"X partners with Y\", \"X collaborates with Y\"\n",
        "- Service Provision: \"X provides services to Y\", \"X trains Y\"\n",
        "- Creation/Launch: \"X launches Y\", \"X establishes Y\"\n",
        "- Selection/Awards: \"X selects Y\", \"X awards Y\"\n",
        "\n",
        "WHAT TO IGNORE:\n",
        "- Presentations, meetings, speeches (\"presented to\", \"spoke at\", \"attended\")\n",
        "- Generic updates (\"informed\", \"updated\", \"announced\")\n",
        "- Internal governance (\"appointed\", \"elected\", \"thanked\")\n",
        "- Abstract/vague actions (\"focus on\", \"work towards\", \"aim to\")\n",
        "\n",
        "RULES:\n",
        "- \"role_identity\": The organization taking action (be specific: \"EIT Digital\", not just \"EIT\")\n",
        "- \"practice\": ONE clear action verb or short verb phrase (2-4 words max)\n",
        "- \"counterrole\": The specific recipient/beneficiary (not vague terms like \"Europe\" or \"stakeholders\")\n",
        "- Split multiple counterroles into separate triplets\n",
        "\n",
        "GOOD EXAMPLES:\n",
        "\"EIT InnoEnergy invested €2.5 million in cleantech startup Northvolt to scale battery production.\"\n",
        "→ Role: EIT InnoEnergy\n",
        "→ Practice: invests in\n",
        "→ Counterrole: Northvolt\n",
        "\n",
        "\"EIT Digital Accelerator supports over 200 scaleups annually through mentorship and market access.\"\n",
        "→ Role: EIT Digital Accelerator\n",
        "→ Practice: supports\n",
        "→ Counterrole: scaleups\n",
        "\n",
        "\"Climate-KIC partners with major European cities to develop climate adaptation strategies.\"\n",
        "→ Role: Climate-KIC\n",
        "→ Practice: partners with\n",
        "→ Counterrole: European cities\n",
        "\n",
        "\"EIT Health awards funding to healthcare startups through the Headstart programme.\"\n",
        "→ Role: EIT Health\n",
        "→ Practice: awards funding to\n",
        "→ Counterrole: healthcare startups\n",
        "\n",
        "BAD EXAMPLES (DO NOT EXTRACT):\n",
        "\"The Chairman presented the strategy to the Board\" ❌ (presentation, not strategic practice)\n",
        "\"EIT focuses on innovation in Europe\" ❌ (too vague)\n",
        "\"The Director thanked the participants\" ❌ (social courtesy, not institutional practice)\n",
        "\n",
        "RETURN FORMAT:\n",
        "Role: [specific organization]\n",
        "Practice: [action verb phrase]\n",
        "Counterrole: [specific recipient]\n",
        "---\n",
        "\n",
        "TEXT TO ANALYZE:\n",
        "{filtered_text}\n",
        "\n",
        "Extract ONLY strategic, ongoing organizational practices:\"\"\"\n",
        "            prompts.append(prompt)\n",
        "        return prompts\n",
        "\n",
        "    def parse_responses(self, docs: Iterable[Doc], responses: Iterable[str]):\n",
        "        docs_list = list(docs)\n",
        "        responses_list = list(responses)\n",
        "\n",
        "        # Expanded list of weak/reporting verbs to filter out\n",
        "        weak_practices = {\n",
        "            'presents', 'presented', 'presents to', 'present to', 'present',\n",
        "            'announces', 'announced', 'announces to', 'inform', 'informs', 'informed',\n",
        "            'updates', 'updated', 'update', 'speaks', 'spoke', 'speak',\n",
        "            'attends', 'attended', 'attend', 'discusses', 'discussed', 'discuss',\n",
        "            'meets', 'met', 'meet', 'thanks', 'thanked', 'thank',\n",
        "            'appoints', 'appointed', 'appoint', 'elects', 'elected', 'elect',\n",
        "            'is', 'are', 'was', 'were', 'be', 'being', 'been',\n",
        "            'focuses', 'focused', 'focus', 'aims', 'aimed', 'aim',\n",
        "            'explains', 'explained', 'explain', 'showcases', 'showcased',\n",
        "            'assured', 'assures', 'bringing forward', 'making success'\n",
        "        }\n",
        "\n",
        "        # Generic/vague counterroles to filter\n",
        "        vague_counterroles = {\n",
        "            'europe', 'stakeholders', 'participants', 'audiences', 'parties',\n",
        "            'community', 'public', 'society', 'world', 'people'\n",
        "        }\n",
        "\n",
        "        for doc, response in zip(docs_list, responses_list):\n",
        "            if \"No relationships found\" in response or \"Error generating\" in response:\n",
        "                doc._.triplets = []\n",
        "                continue\n",
        "\n",
        "            triplets = []\n",
        "            current = {}\n",
        "\n",
        "            for line in response.strip().split('\\n'):\n",
        "                line = line.strip()\n",
        "                if line.startswith('Role:'):\n",
        "                    current = {'role': line.replace('Role:', '').strip()}\n",
        "                elif line.startswith('Practice:'):\n",
        "                    current['practice'] = line.replace('Practice:', '').strip()\n",
        "                elif line.startswith('Counterrole:'):\n",
        "                    current['counterrole'] = line.replace('Counterrole:', '').strip()\n",
        "\n",
        "                    # STRICT validation\n",
        "                    if len(current) == 3:\n",
        "                        practice_lower = current['practice'].lower().strip()\n",
        "                        counterrole_lower = current['counterrole'].lower().strip()\n",
        "\n",
        "                        # Filter out weak practices and vague counterroles\n",
        "                        if (practice_lower not in weak_practices and\n",
        "                            counterrole_lower not in vague_counterroles and\n",
        "                            len(current['role']) > 2 and\n",
        "                            len(current['counterrole']) > 2 and\n",
        "                            len(current['practice']) > 2):\n",
        "                            triplets.append(current)\n",
        "                    current = {}\n",
        "\n",
        "            doc._.triplets = triplets\n",
        "\n",
        "        return iter(docs_list)"
      ],
      "metadata": {
        "id": "889_s9sxIQwA"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    \"task\": {\"@llm_tasks\": \"custom.TripletExtraction.v1\"},\n",
        "    \"model\": {\n",
        "        \"@llm_models\": \"custom.Gemini.v1\",\n",
        "        \"api_key\": gemini_key\n",
        "    },\n",
        "    \"validate_types\": False\n",
        "}\n"
      ],
      "metadata": {
        "id": "mwRYWnPyITVo"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/combined_with_dates.txt\" ,\"r\") as file:\n",
        "  text = file.read()"
      ],
      "metadata": {
        "id": "J-WAJD-8IWsy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.blank(\"en\")\n",
        "nlp.add_pipe(\"sentencizer\")\n",
        "nlp.add_pipe(\"llm\", config=config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oj0TcqwIYnk",
        "outputId": "96d141a9-0db6-4d44-fc0f-e39f2987d5ee"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Gemini...\n",
            "Gemini ready\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy_llm.pipeline.llm.LLMWrapper at 0x78ffc65f3610>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_text(text, chunk_size=2500):\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    for i in range(0, len(words), chunk_size):\n",
        "        chunk = \" \".join(words[i:i+chunk_size+300])\n",
        "        chunks.append(chunk)\n",
        "    return chunks\n",
        "\n",
        "print(\"\\nFiltering for high-quality sentences with meaningful actions...\")\n",
        "text_chunks = chunk_text(text, chunk_size=2500)\n",
        "print(f\"Created {len(text_chunks)} chunks to process\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvfPGQZxIlwp",
        "outputId": "07ed63f7-0d42-4dbd-d193-2b4f2441c317"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Filtering for high-quality sentences with meaningful actions...\n",
            "Created 30 chunks to process\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Process chunks\n",
        "all_triplets = []\n",
        "for i, chunk in enumerate(text_chunks, 1):\n",
        "    print(f\"Processing chunk {i}/{len(text_chunks)}...\", end=\" \")\n",
        "    try:\n",
        "        doc = nlp(chunk)\n",
        "        chunk_triplets = doc._.triplets\n",
        "        all_triplets.extend(chunk_triplets)\n",
        "        print(f\"Found {len(chunk_triplets)} quality triplets\")\n",
        "    except Exception as e:\n",
        "        print(f\"✗ Error: {e}\")\n",
        "        continue\n",
        "\n",
        "# Display results\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"EXTRACTED STRATEGIC ORGANIZATIONAL TRIPLETS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for i, t in enumerate(all_triplets, 1):\n",
        "    print(f\"\\n{i}.\")\n",
        "    print(f\"  Role Identity:  {t['role']}\")\n",
        "    print(f\"  Practice:       {t['practice']}\")\n",
        "    print(f\"  Counterrole:    {t['counterrole']}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(f\"TOTAL HIGH-QUALITY TRIPLETS: {len(all_triplets)}\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Save outputs\n",
        "with open(\"/content/extracted_triplets.txt\", \"w\") as f:\n",
        "    for i, t in enumerate(all_triplets, 1):\n",
        "        f.write(f\"{i}. {t['role']} -> {t['practice']} -> {t['counterrole']}\\n\")\n",
        "\n",
        "print(\"\\n Files saved:\")\n",
        "print(\"   - extracted_triplets.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bkkqE9uFIoGF",
        "outputId": "880676ba-404e-4c55-f93a-a14b6da0e871"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing chunk 1/30... Found 0 quality triplets\n",
            "Processing chunk 2/30... Found 0 quality triplets\n",
            "Processing chunk 3/30... Found 0 quality triplets\n",
            "Processing chunk 4/30... Found 2 quality triplets\n",
            "Processing chunk 5/30... Found 6 quality triplets\n",
            "Processing chunk 6/30... Found 6 quality triplets\n",
            "Processing chunk 7/30... Found 3 quality triplets\n",
            "Processing chunk 8/30... Found 0 quality triplets\n",
            "Processing chunk 9/30... Found 0 quality triplets\n",
            "Processing chunk 10/30... Found 0 quality triplets\n",
            "Processing chunk 11/30... Found 3 quality triplets\n",
            "Processing chunk 12/30... Found 0 quality triplets\n",
            "Processing chunk 13/30... Found 0 quality triplets\n",
            "Processing chunk 14/30... Found 0 quality triplets\n",
            "Processing chunk 15/30... Found 0 quality triplets\n",
            "Processing chunk 16/30... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash-lite:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 228.58ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error generating content: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15\n",
            "Please retry in 14.027285886s.\n",
            "Found 0 quality triplets\n",
            "Processing chunk 17/30... Found 14 quality triplets\n",
            "Processing chunk 18/30... Found 5 quality triplets\n",
            "Processing chunk 19/30... Found 0 quality triplets\n",
            "Processing chunk 20/30... Found 0 quality triplets\n",
            "Processing chunk 21/30... Found 0 quality triplets\n",
            "Processing chunk 22/30... Found 0 quality triplets\n",
            "Processing chunk 23/30... Found 0 quality triplets\n",
            "Processing chunk 24/30... Found 0 quality triplets\n",
            "Processing chunk 25/30... Found 0 quality triplets\n",
            "Processing chunk 26/30... Found 0 quality triplets\n",
            "Processing chunk 27/30... Found 2 quality triplets\n",
            "Processing chunk 28/30... Found 4 quality triplets\n",
            "Processing chunk 29/30... Found 0 quality triplets\n",
            "Processing chunk 30/30... Found 0 quality triplets\n",
            "\n",
            "================================================================================\n",
            "EXTRACTED STRATEGIC ORGANIZATIONAL TRIPLETS\n",
            "================================================================================\n",
            "\n",
            "1.\n",
            "  Role Identity:  EIT ICT Labs\n",
            "  Practice:       winner of\n",
            "  Counterrole:    Trifense\n",
            "\n",
            "2.\n",
            "  Role Identity:  EIT Awards\n",
            "  Practice:       winner of\n",
            "  Counterrole:    Trifense\n",
            "\n",
            "3.\n",
            "  Role Identity:  jury\n",
            "  Practice:       selected\n",
            "  Counterrole:    organisations\n",
            "\n",
            "4.\n",
            "  Role Identity:  EIT\n",
            "  Practice:       celebrates\n",
            "  Counterrole:    innovation\n",
            "\n",
            "5.\n",
            "  Role Identity:  EIT\n",
            "  Practice:       celebrates\n",
            "  Counterrole:    entrepreneurship\n",
            "\n",
            "6.\n",
            "  Role Identity:  EIT Awards 2013\n",
            "  Practice:       announcement of the winners\n",
            "  Counterrole:    winners\n",
            "\n",
            "7.\n",
            "  Role Identity:  EIT Awards\n",
            "  Practice:       highlight\n",
            "  Counterrole:    ideas\n",
            "\n",
            "8.\n",
            "  Role Identity:  EIT Awards\n",
            "  Practice:       highlight\n",
            "  Counterrole:    start ups\n",
            "\n",
            "9.\n",
            "  Role Identity:  EIT Awards\n",
            "  Practice:       showcase potential and talent of\n",
            "  Counterrole:    young members of the EIT/KIC community\n",
            "\n",
            "10.\n",
            "  Role Identity:  EIT Awards\n",
            "  Practice:       inspire through\n",
            "  Counterrole:    role models\n",
            "\n",
            "11.\n",
            "  Role Identity:  EIT Awards\n",
            "  Practice:       promote entrepreneurial and innovation mind-set\n",
            "  Counterrole:    KIC ventures\n",
            "\n",
            "12.\n",
            "  Role Identity:  EIT Awards\n",
            "  Practice:       promote entrepreneurial and innovation mind-set\n",
            "  Counterrole:    Next Generation of Change Agents and Entrepreneurs\n",
            "\n",
            "13.\n",
            "  Role Identity:  EIT Awards\n",
            "  Practice:       provide platform for\n",
            "  Counterrole:    mutual inspiration\n",
            "\n",
            "14.\n",
            "  Role Identity:  EIT Awards\n",
            "  Practice:       provide platform for\n",
            "  Counterrole:    entrepreneurial opportunities\n",
            "\n",
            "15.\n",
            "  Role Identity:  EIT\n",
            "  Practice:       launches\n",
            "  Counterrole:    EIT Awards\n",
            "\n",
            "16.\n",
            "  Role Identity:  EIT\n",
            "  Practice:       highlight\n",
            "  Counterrole:    entrepreneurial start-ups\n",
            "\n",
            "17.\n",
            "  Role Identity:  EIT\n",
            "  Practice:       showcase\n",
            "  Counterrole:    talent\n",
            "\n",
            "18.\n",
            "  Role Identity:  Climate-KIC\n",
            "  Practice:       alumni of\n",
            "  Counterrole:    Nerdalize\n",
            "\n",
            "19.\n",
            "  Role Identity:  Nerdalize\n",
            "  Practice:       expanding collaboration with\n",
            "  Counterrole:    Eneco\n",
            "\n",
            "20.\n",
            "  Role Identity:  EIT Awards\n",
            "  Practice:       Winner\n",
            "  Counterrole:    Nerdalize\n",
            "\n",
            "21.\n",
            "  Role Identity:  EIT Climate-KIC\n",
            "  Practice:       supported\n",
            "  Counterrole:    Lilium\n",
            "\n",
            "22.\n",
            "  Role Identity:  EIT RawMaterials\n",
            "  Practice:       partner\n",
            "  Counterrole:    VTT\n",
            "\n",
            "23.\n",
            "  Role Identity:  EIT Climate-KIC\n",
            "  Practice:       supported\n",
            "  Counterrole:    TWAICE\n",
            "\n",
            "24.\n",
            "  Role Identity:  EIT Health\n",
            "  Practice:       pledges\n",
            "  Counterrole:    COVID-19 solutions\n",
            "\n",
            "25.\n",
            "  Role Identity:  EIT Digital\n",
            "  Practice:       awards\n",
            "  Counterrole:    Data against COVID-19 Deephack\n",
            "\n",
            "26.\n",
            "  Role Identity:  EIT Climate-KIC\n",
            "  Practice:       supported\n",
            "  Counterrole:    Climeworks\n",
            "\n",
            "27.\n",
            "  Role Identity:  EIT Urban Mobility\n",
            "  Practice:       welcomes\n",
            "  Counterrole:    Scale-Up Hub members\n",
            "\n",
            "28.\n",
            "  Role Identity:  EIT Digital\n",
            "  Practice:       receive applications for\n",
            "  Counterrole:    Challenge 2020 scale-ups\n",
            "\n",
            "29.\n",
            "  Role Identity:  EIT Manufacturing\n",
            "  Practice:       awarded\n",
            "  Counterrole:    Covid-19 tackle\n",
            "\n",
            "30.\n",
            "  Role Identity:  EIT Climate-KIC\n",
            "  Practice:       receives\n",
            "  Counterrole:    innovation projects\n",
            "\n",
            "31.\n",
            "  Role Identity:  EIT Food\n",
            "  Practice:       announces recipients of\n",
            "  Counterrole:    COVID-19 Innovation Fund\n",
            "\n",
            "32.\n",
            "  Role Identity:  EIT RawMaterials\n",
            "  Practice:       granted\n",
            "  Counterrole:    innovators\n",
            "\n",
            "33.\n",
            "  Role Identity:  EIT Digital\n",
            "  Practice:       compete for\n",
            "  Counterrole:    EIT Awards 2020 innovations\n",
            "\n",
            "34.\n",
            "  Role Identity:  EIT Health\n",
            "  Practice:       start-ups raise\n",
            "  Counterrole:    EUR 72.7 million\n",
            "\n",
            "35.\n",
            "  Role Identity:  EIT Health\n",
            "  Practice:       raise funding\n",
            "  Counterrole:    start-ups\n",
            "\n",
            "36.\n",
            "  Role Identity:  EIT Digital Challenge\n",
            "  Practice:       awards\n",
            "  Counterrole:    European digital deep-tech scale-ups\n",
            "\n",
            "37.\n",
            "  Role Identity:  EIT Digital\n",
            "  Practice:       attracts investment\n",
            "  Counterrole:    Scotland\n",
            "\n",
            "38.\n",
            "  Role Identity:  European Food Safety Authority\n",
            "  Practice:       launched hackathon\n",
            "  Counterrole:    EIT Alumni\n",
            "\n",
            "39.\n",
            "  Role Identity:  EIT\n",
            "  Practice:       announced winners\n",
            "  Counterrole:    2020 EIT Awards\n",
            "\n",
            "40.\n",
            "  Role Identity:  EIT Climate-KIC\n",
            "  Practice:       portfolio includes\n",
            "  Counterrole:    Naked Energy\n",
            "\n",
            "41.\n",
            "  Role Identity:  Naked Energy\n",
            "  Practice:       awards winner\n",
            "  Counterrole:    British Library\n",
            "\n",
            "42.\n",
            "  Role Identity:  EIT Awards\n",
            "  Practice:       winner\n",
            "  Counterrole:    Naked Energy\n",
            "\n",
            "43.\n",
            "  Role Identity:  EIT Climate-KIC\n",
            "  Practice:       portfolio\n",
            "  Counterrole:    Naked Energy\n",
            "\n",
            "44.\n",
            "  Role Identity:  EIT Governing Board\n",
            "  Practice:       Chairperson\n",
            "  Counterrole:    Stefan Dobrev\n",
            "\n",
            "45.\n",
            "  Role Identity:  EIT Awards Categories\n",
            "  Practice:       recognise\n",
            "  Counterrole:    leaders\n",
            "\n",
            "================================================================================\n",
            "TOTAL HIGH-QUALITY TRIPLETS: 45\n",
            "================================================================================\n",
            "\n",
            " Files saved:\n",
            "   - extracted_triplets.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B0HPTOuiJjDC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}